{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b7f00d",
   "metadata": {},
   "source": [
    "# [SQL Interview Questions on Data Lemur - Easy](https://datalemur.com/questions?difficulty=Easy&category=SQL)\n",
    "\n",
    "##### Solved by: Dorothy Kunth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754840b",
   "metadata": {},
   "source": [
    "### 1. [Histogram of Tweets - Twitter](https://datalemur.com/questions/sql-histogram-tweets)\n",
    "\n",
    "Assume you're given a table Twitter tweet data, write a query to obtain a histogram of tweets posted per user in 2022. Output the tweet count per user as the bucket and the number of Twitter users who fall into that bucket.\n",
    "\n",
    "In other words, group the users by the number of tweets they posted in 2022 and count the number of users in each group.\n",
    "\n",
    "``tweets`` table\n",
    "\n",
    "| tweet_id | user_id | msg                                                               | tweet_date          |\n",
    "|----------|---------|-------------------------------------------------------------------|---------------------|\n",
    "| 241425   | 254     | If the salary is so competitive why wonâ€™t you tell me what it is? | 03/01/2022 11:00:00 |\n",
    "| 214252   | 111     | Am considering taking Tesla private at $420. Funding secured.     | 12/30/2021 00:00:00 |\n",
    "| 739252   | 111     | Despite the constant negative press covfefe                       | 01/01/2022 11:00:00 |\n",
    "| 846402   | 111     | Following @NickSinghTech on Twitter changed my life!              | 02/14/2022 11:00:00 |\n",
    "| 231574   | 148     | I no longer have a manager. I can't be managed                    | 03/23/2022 11:00:00 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a12d7",
   "metadata": {},
   "source": [
    "### Solution\n",
    "1. Query the number of tweets per user in 2022\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    user_id,\n",
    "    COUNT(tweet_id) AS tweet_count\n",
    "FROM tweets\n",
    "WHERE tweet_date BETWEEN '01/01/2022' AND '12/31/2022'\n",
    "GROUP BY 1\n",
    "```\n",
    "| user_id | tweet_count |\n",
    "|---------|-------------|\n",
    "| 111     | 2           |\n",
    "| 148     | 1           |\n",
    "| 254     | 1           |\n",
    "\n",
    "\n",
    "<br><br>\n",
    "2. Use the above query as an inline query (FROM clause) and use the ``tweet_count`` as bucket then count the number of users per bucket\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  tweet_count AS bucket,\n",
    "  COUNT(user_id) num_users\n",
    "FROM (\n",
    "  SELECT \n",
    "   user_id,\n",
    "   COUNT(tweet_id) AS tweet_count\n",
    "  FROM tweets\n",
    "  WHERE tweet_date BETWEEN '01/01/2022' AND '12/31/2022'\n",
    "  GROUP BY 1) AS tweet_count_per_user\n",
    "GROUP BY 1\n",
    "```\n",
    "| bucket | num_users |\n",
    "|--------|-----------|\n",
    "| 1      | 2         |\n",
    "| 2      | 1         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf44ca",
   "metadata": {},
   "source": [
    "### 2. [Data Science Skills - LinkedIn](https://datalemur.com/questions/matching-skills)\n",
    "\n",
    "Given a table of candidates and their skills, you're tasked with finding the candidates best suited for an open Data Science job. You want to find candidates who are proficient in Python, Tableau, and PostgreSQL.\n",
    "\n",
    "Write a query to list the candidates who possess all of the required skills for the job. Sort the output by candidate ID in ascending order.\n",
    "\n",
    "Assumption: There are no duplicates in the candidates table.\n",
    "\n",
    "``candidates`` table\n",
    "\n",
    "| candidate_id | skill      |\n",
    "|--------------|------------|\n",
    "| 123          | Python     |\n",
    "| 123          | Tableau    |\n",
    "| 123          | PostgreSQL |\n",
    "| 234          | R          |\n",
    "| 234          | PowerBI    |\n",
    "| 234          | SQL Server |\n",
    "| 345          | Python     |\n",
    "| 345          | Tableau    |\n",
    "| 147          | Python     |\n",
    "| 147          | PostgreSQL |\n",
    "| 147          | Tableau    |\n",
    "| 147          | Java       |\n",
    "| 168          | Python     |\n",
    "| 256          | Tableau    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2100a5a",
   "metadata": {},
   "source": [
    "### Solution\n",
    "1. Select all the candidates that have skills in Python, Tableau, and PostgreSQL\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM candidates\n",
    "WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')\n",
    "ORDER BY candidate_id\n",
    "```\n",
    "| candidate_id | skill      |\n",
    "|--------------|------------|\n",
    "| 123          | Python     |\n",
    "| 123          | Tableau    |\n",
    "| 123          | PostgreSQL |\n",
    "| 147          | Python     |\n",
    "| 147          | PostgreSQL |\n",
    "| 147          | Tableau    |\n",
    "| 168          | Python     |\n",
    "| 256          | Tableau    |\n",
    "| 345          | Tableau    |\n",
    "| 345          | Python     |\n",
    "\n",
    "<br><br>\n",
    "2. Use the above query as an inline query (FROM clause), group by ``candidate_id`` then use HAVING clause to filter only the count of ``skill`` to 3\n",
    "\n",
    "```sql\n",
    "SELECT candidate_id\n",
    "FROM (SELECT *\n",
    "      FROM candidates\n",
    "      WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')\n",
    "      ORDER BY candidate_id) AS skillset\n",
    "GROUP BY candidate_id\n",
    "HAVING COUNT(skill) = 3\n",
    "ORDER BY candidate_id;\n",
    "```\n",
    "| candidate_id |\n",
    "|--------------|\n",
    "| 123          |\n",
    "| 147          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afca4bc",
   "metadata": {},
   "source": [
    "### 3. [Page With No Likes - Facebook](https://datalemur.com/questions/sql-page-with-no-likes)\n",
    "\n",
    "Assume you're given two tables containing data about Facebook Pages and their respective likes (as in \"Like a Facebook Page\").\n",
    "\n",
    "Write a query to return the IDs of the Facebook pages that have zero likes. The output should be sorted in ascending order based on the page IDs.\n",
    "\n",
    "``pages`` table\n",
    "\n",
    "| page_id | page_name              |\n",
    "|---------|------------------------|\n",
    "| 20001   | SQL Solutions          |\n",
    "| 20045   | Brain Exercises        |\n",
    "| 20701   | Tips for Data Analysts |\n",
    "| 31111   | Postgres Crash Course  |\n",
    "| 32728   | Break the thread       |\n",
    "\n",
    "\n",
    "``page_likes`` table\n",
    "\n",
    "| user_id | page_id | liked_date          |\n",
    "|---------|---------|---------------------|\n",
    "| 111     | 20001   | 04/08/2022 00:00:00 |\n",
    "| 121     | 20045   | 03/12/2022 00:00:00 |\n",
    "| 156     | 20001   | 07/25/2022 00:00:00 |\n",
    "| 255     | 20045   | 07/19/2022 00:00:00 |\n",
    "| 125     | 20001   | 07/19/2022 00:00:00 |\n",
    "| 144     | 31111   | 06/21/2022 00:00:00 |\n",
    "| 125     | 31111   | 07/04/2022 00:00:00 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903cfa7b",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "```sql\n",
    "SELECT p.page_id\n",
    "FROM pages AS p\n",
    "LEFT JOIN page_likes AS pl \n",
    "ON p.page_id = pl.page_id\n",
    "WHERE liked_date IS NULL\n",
    "ORDER BY p.page_id\n",
    "```\n",
    "| page_id |\n",
    "|---------|\n",
    "| 20701   |\n",
    "| 32728   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4baa84d",
   "metadata": {},
   "source": [
    "### 4. [Unfinished Parts - Tesla](https://datalemur.com/questions/tesla-unfinished-parts)\n",
    "\n",
    "Tesla is investigating production bottlenecks and they need your help to extract the relevant data. Write a query to determine which parts have begun the assembly process but are not yet finished.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- parts_assembly table contains all parts currently in production, each at varying stages of the assembly process.\n",
    "- An unfinished part is one that lacks a finish_date.\n",
    "\n",
    "``parts_assembly`` table\n",
    "\n",
    "| part    | finish_date         | assembly_step |\n",
    "|---------|---------------------|---------------|\n",
    "| battery | 01/22/2022 00:00:00 | 1             |\n",
    "| battery | 02/22/2022 00:00:00 | 2             |\n",
    "| battery | 03/22/2022 00:00:00 | 3             |\n",
    "| bumper  | 01/22/2022 00:00:00 | 1             |\n",
    "| bumper  | 02/22/2022 00:00:00 | 2             |\n",
    "| bumper  | NULL                | 3             |\n",
    "| bumper  | NULL                | 4             |\n",
    "| door    | 01/22/2022 00:00:00 | 1             |\n",
    "| door    | 02/22/2022 00:00:00 | 2             |\n",
    "| engine  | 01/01/2022 00:00:00 | 1             |\n",
    "| engine  | 01/25/2022 00:00:00 | 2             |\n",
    "| engine  | 02/28/2022 00:00:00 | 3             |\n",
    "| engine  | 04/01/2022 00:00:00 | 4             |\n",
    "| engine  | NULL                | 5             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded3517",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "```sql\n",
    "SELECT part, assembly_step\n",
    "FROM parts_assembly\n",
    "WHERE finish_date IS NULL;\n",
    "```\n",
    "| part   | assembly_step |\n",
    "|--------|---------------|\n",
    "| bumper | 3             |\n",
    "| bumper | 4             |\n",
    "| engine | 5             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32639097",
   "metadata": {},
   "source": [
    "### 5. [Laptop vs. Mobile Viewership - The New York Times](https://datalemur.com/questions/laptop-mobile-viewership)\n",
    "\n",
    "Assume you're given the table on user viewership categorised by device type where the three types are laptop, tablet, and phone.\n",
    "\n",
    "Write a query that calculates the total viewership for laptops and mobile devices where mobile is defined as the sum of tablet and phone viewership. Output the total viewership for laptops as laptop_views and the total viewership for mobile devices as mobile_views.\n",
    "\n",
    "``viewership`` table\n",
    "\n",
    "| user_id | device_type | view_time           | lap_mob | device_family | laptop_views | mobile_views | mobile |\n",
    "|---------|-------------|---------------------|---------|---------------|--------------|--------------|--------|\n",
    "| 123     | tablet      | 01/02/2022 00:00:00 | NULL    | NULL          | NULL         | NULL         | NULL   |\n",
    "| 125     | laptop      | 01/07/2022 00:00:00 | NULL    | NULL          | NULL         | NULL         | NULL   |\n",
    "| 128     | laptop      | 02/09/2022 00:00:00 | NULL    | NULL          | NULL         | NULL         | NULL   |\n",
    "| 129     | phone       | 02/09/2022 00:00:00 | NULL    | NULL          | NULL         | NULL         | NULL   |\n",
    "| 145     | tablet      | 02/24/2022 00:00:00 | NULL    | NULL          | NULL         | NULL         | NULL   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0a6b8",
   "metadata": {},
   "source": [
    "### Solution 1 \n",
    "1. Create a case statement\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END AS laptop_views,\n",
    "  CASE WHEN device_type IN ('phone', 'tablet') THEN 1 ELSE 0 END AS mobile_views\n",
    "FROM viewership\n",
    "```\n",
    "| laptop_views | mobile_views |   |   |   |   |   |   |\n",
    "|--------------|--------------|---|---|---|---|---|---|\n",
    "| 0            | 1            |   |   |   |   |   |   |\n",
    "| 1            | 0            |   |   |   |   |   |   |\n",
    "| 1            | 0            |   |   |   |   |   |   |\n",
    "| 0            | 1            |   |   |   |   |   |   |\n",
    "| 0            | 1            |   |   |   |   |   |   |\n",
    "\n",
    "<br><br>\n",
    "2. Use the above query as an inline query (FROM clause) and sum both views\n",
    "\n",
    "```sql\n",
    "SELECT SUM(laptop_views) AS laptop_views, SUM(mobile_views) AS mobile_views\n",
    "FROM (\n",
    "  SELECT \n",
    "    CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END AS laptop_views,\n",
    "    CASE WHEN device_type IN ('phone', 'tablet') THEN 1 ELSE 0 END AS mobile_views\n",
    "  FROM viewership) AS views\n",
    "```\n",
    "| laptop_views | mobile_views |\n",
    "|--------------|--------------|\n",
    "| 2            | 3            |\n",
    "\n",
    "\n",
    "### Solution 2\n",
    "```sql\n",
    "SELECT \n",
    "    SUM(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views, \n",
    "    SUM(CASE WHEN device_type IN ('phone', 'tablet') THEN 1 ELSE 0 END) AS mobile_views\n",
    "FROM viewership\n",
    "```\n",
    "| laptop_views | mobile_views |\n",
    "|--------------|--------------|\n",
    "| 2            | 3            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614e70e",
   "metadata": {},
   "source": [
    "### 6. [Average Post Hiatus - Facebook](https://datalemur.com/questions/sql-average-post-hiatus-1)\n",
    "\n",
    "Given a table of Facebook posts, for each user who posted at least twice in 2021, write a query to find the number of days between each userâ€™s first post of the year and last post of the year in the year 2021. Output the user and number of the days between each user's first and last post.\n",
    "\n",
    "``posts`` table\n",
    "\n",
    "| user_id | post_id | post_content                                                                                                                            | post_date           | difference |\n",
    "|---------|---------|-----------------------------------------------------------------------------------------------------------------------------------------|---------------------|------------|\n",
    "| 151652  | 111766  | it's always winter, but never Christmas.                                                                                                | 12/01/2021 11:00:00 | NULL       |\n",
    "| 661093  | 442560  | Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend                        | 09/08/2021 10:00:00 | NULL       |\n",
    "| 661093  | 624356  | Happy valentines!                                                                                                                       | 02/14/2021 00:00:00 | NULL       |\n",
    "| 151652  | 599415  | Need a hug                                                                                                                              | 01/28/2021 00:00:00 | NULL       |\n",
    "| 178425  | 157336  | I'm so done with these restrictions - I want to travel!!!                                                                               | 03/24/2021 11:00:00 | NULL       |\n",
    "| 423967  | 784254  | Just going to cry myself to sleep after watching Marley and Me.                                                                         | 05/05/2021 00:00:00 | NULL       |\n",
    "| 151325  | 613451  | Happy new year all my friends!                                                                                                          | 01/01/2022 11:00:00 | NULL       |\n",
    "| 151325  | 987562  | The global surface temperature for June 2022 was the sixth-highest in the 143-year record. This is definitely global warming happening. | 07/01/2022 10:00:00 | NULL       |\n",
    "| 661093  | 674356  | Can't wait to start my freshman year - super excited!                                                                                   | 08/18/2021 10:00:00 | NULL       |\n",
    "| 151325  | 451464  | Garage sale this Saturday 1 PM. All welcome to check out!                                                                               | 10/25/2021 10:00:00 | NULL       |\n",
    "| 151652  | 994156  | Does anyone have an extra iPhone charger to sell?                                                                                       | 04/01/2021 10:00:00 | NULL       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19ba13",
   "metadata": {},
   "source": [
    "### Solution 1 \n",
    "Cast the ``post_date`` to DATE then get the difference between the MAX and MIN dates. Then filter to year 2021 and where number of ``post_id`` is > 1\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "\tuser_id, \n",
    "    MAX(CAST(post_date AS DATE)) - MIN(CAST(post_date AS DATE)) AS days_between\n",
    "FROM posts\n",
    "WHERE DATE_PART('year', post_date) = 2021 \n",
    "GROUP BY user_id\n",
    "HAVING COUNT(post_id) > 1;\n",
    "```\n",
    "| user_id | days_between |\n",
    "|---------|--------------|\n",
    "| 151652  | 307          |\n",
    "| 661093  | 206          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3837b",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "\n",
    "1. Use window function LEAD on ``post_date`` to get the subsequent row as ``next_post_date``. Then filter to year 2021\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  user_id, \n",
    "  post_id, \n",
    "  post_date, \n",
    "  LEAD(post_date) OVER (PARTITION BY user_id ORDER BY post_date) AS next_post_date\n",
    "FROM posts\n",
    "WHERE DATE_PART('year', post_date) = 2021\n",
    "ORDER BY 1, 3\n",
    "```\n",
    "| user_id | post_id | post_date           | next_post_date      |\n",
    "|---------|---------|---------------------|---------------------|\n",
    "| 151325  | 451464  | 10/25/2021 10:00:00 | NULL                |\n",
    "| 151652  | 599415  | 01/28/2021 00:00:00 | 04/01/2021 10:00:00 |\n",
    "| 151652  | 994156  | 04/01/2021 10:00:00 | 12/01/2021 11:00:00 |\n",
    "| 151652  | 111766  | 12/01/2021 11:00:00 | NULL                |\n",
    "| 178425  | 157336  | 03/24/2021 11:00:00 | NULL                |\n",
    "| 423967  | 784254  | 05/05/2021 00:00:00 | NULL                |\n",
    "| 661093  | 624356  | 02/14/2021 00:00:00 | 08/18/2021 10:00:00 |\n",
    "| 661093  | 674356  | 08/18/2021 10:00:00 | 09/08/2021 10:00:00 |\n",
    "| 661093  | 442560  | 09/08/2021 10:00:00 | NULL                |\n",
    "\n",
    "\n",
    "\n",
    "2. Use the above query as an inline query (FROM clause) and sum the days between ``next_post_date`` and ``post_date``. Then filter where ``next_post_date`` is not null.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "user_id,\n",
    "SUM(DATE_PART('day', next_post_date - post_date)) AS days_between\n",
    "FROM (\n",
    "  SELECT \n",
    "    user_id, \n",
    "    post_id, \n",
    "    post_date, \n",
    "    LEAD(post_date) OVER (PARTITION BY user_id ORDER BY post_date) AS next_post_date\n",
    "  FROM posts\n",
    "  WHERE DATE_PART('year', post_date) = 2021\n",
    "  ORDER BY 1, 3) AS user_post_2021\n",
    "WHERE next_post_date IS NOT NULL\n",
    "GROUP BY 1\n",
    "```\n",
    "| user_id | days_between |\n",
    "|---------|--------------|\n",
    "| 151652  | 307          |\n",
    "| 661093  | 206          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d723ad5",
   "metadata": {},
   "source": [
    "### 7. [Teams Power Users - Microsoft](https://datalemur.com/questions/teams-power-users)\n",
    "Write a query to identify the top 2 Power Users who sent the highest number of messages on Microsoft Teams in August 2022. Display the IDs of these 2 users along with the total number of messages they sent. Output the results in descending order based on the count of the messages.\n",
    "\n",
    "Assumption:\n",
    "\n",
    "No two users have sent the same number of messages in August 2022.\n",
    "\n",
    "``messages`` table\n",
    "\n",
    "| message_id | sender_id | receiver_id | content                                       | sent_date           | message_count |\n",
    "|------------|-----------|-------------|-----------------------------------------------|---------------------|---------------|\n",
    "| 901        | 3601      | 4500        | You up?                                       | 08/03/2022 16:43:00 | NULL          |\n",
    "| 743        | 3601      | 8752        | Let's take this offline                       | 06/14/2022 14:30:00 | NULL          |\n",
    "| 888        | 3601      | 7855        | DataLemur has awesome user base!              | 08/12/2022 08:45:00 | NULL          |\n",
    "| 100        | 2520      | 6987        | Send this out now!                            | 08/16/2021 00:35:00 | NULL          |\n",
    "| 898        | 2520      | 9630        | Are you ready for your upcoming presentation? | 08/13/2022 14:35:00 | NULL          |\n",
    "| 990        | 2520      | 8520        | Maybe it was done by the automation process.  | 08/19/2022 06:30:00 | NULL          |\n",
    "| 819        | 2310      | 4500        | What's the status on this?                    | 07/10/2022 15:55:00 | NULL          |\n",
    "| 922        | 3601      | 4500        | Get on the call                               | 08/10/2022 17:03:00 | NULL          |\n",
    "| 942        | 2520      | 3561        | How much do you know about Data Science?      | 08/17/2022 13:44:00 | NULL          |\n",
    "| 966        | 3601      | 7852        | Meet me in five!                              | 08/17/2022 02:20:00 | NULL          |\n",
    "| 902        | 4500      | 3601        | Only if you're buying                         | 08/03/2022 06:50:00 | NULL          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c7af5",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  sender_id, \n",
    "  COUNT(message_id) AS message_count\n",
    "FROM messages\n",
    "WHERE EXTRACT(MONTH FROM sent_date) = 8\n",
    "  AND EXTRACT(YEAR FROM sent_date) = 2022\n",
    "GROUP BY sender_id\n",
    "ORDER BY COUNT(message_id) DESC\n",
    "LIMIT 2\n",
    "```\n",
    "| sender_id | message_count |\n",
    "|-----------|---------------|\n",
    "| 3601      | 4             |\n",
    "| 2520      | 3             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18352a",
   "metadata": {},
   "source": [
    "### 8. [Duplicate Job Listings - LinkedIn](https://datalemur.com/questions/duplicate-job-listings)\n",
    "Assume you're given a table containing job postings from various companies on the LinkedIn platform. Write a query to retrieve the count of companies that have posted duplicate job listings.\n",
    "\n",
    "Definition:\n",
    "\n",
    "Duplicate job listings are defined as two job listings within the same company that share identical titles and descriptions.\n",
    "\n",
    "``job_listings`` table\n",
    "\n",
    "| company_id | title                         | job_id | description                                                                                                                                                                              |\n",
    "|------------|-------------------------------|--------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 827        | Business Analyst              | 248    | Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.                                             |\n",
    "| 845        | Business Analyst              | 149    | Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.                                             |\n",
    "| 345        | Data Analyst                  | 945    | Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.                                                          |\n",
    "| 345        | Data Analyst                  | 164    | Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.                                                          |\n",
    "| 244        | Data Engineer                 | 172    | Data engineer works in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret. |\n",
    "| 827        | Data Scientist                | 256    | Data scientist uses data to understand and explain the phenomena around them, and help organizations make better decisions.                                                              |\n",
    "| 244        | Software Engineer             | 365    | Software engineers design and create computer systems and applications to solve real-world problems.                                                                                     |\n",
    "| 400        | Business Intelligence Analyst | 674    | Business intelligence analyst reviews data to produce finance and market intelligence reports.                                                                                           |\n",
    "| 827        | Data Scientist                | 245    | Data scientist uses data to understand and explain the phenomena around them, and help organizations make better decisions.                                                              |\n",
    "| 244        | Software Engineer             | 301    | Software engineers design and create computer systems and applications to solve real-world problems.                                                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8a7c2",
   "metadata": {},
   "source": [
    "### Solution\n",
    "1. Since job_id is unique even if the title and description are identical, count the number of job_id grouped by company_id, title, and description\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  company_id, \n",
    "  title, \n",
    "  description, \n",
    "  COUNT(job_id) as job_count\n",
    "FROM job_listings\n",
    "GROUP BY company_id, title, description\n",
    "```\n",
    "| company_id | title                         | description                                                                                                                                                                              | job_count |\n",
    "|------------|-------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|\n",
    "| 827        | Data Scientist                | Data scientist uses data to understand and explain the phenomena around them, and help organizations make better decisions.                                                              | 2         |\n",
    "| 244        | Data Engineer                 | Data engineer works in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret. | 1         |\n",
    "| 845        | Business Analyst              | Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.                                             | 1         |\n",
    "| 244        | Software Engineer             | Software engineers design and create computer systems and applications to solve real-world problems.                                                                                     | 2         |\n",
    "| 345        | Data Analyst                  | Data analyst reviews data to identify key insights into a business's customers and ways the data can be used to solve problems.                                                          | 2         |\n",
    "| 827        | Business Analyst              | Business analyst evaluates past and current business data with the primary goal of improving decision-making processes within organizations.                                             | 1         |\n",
    "| 400        | Business Intelligence Analyst | Business intelligence analyst reviews data to produce finance and market intelligence reports.      | 1         |\n",
    "\n",
    "<br><br>\n",
    "2. Use the above query as an inline query (FROM clause) then count the number of unique companies where job_count is > 1\n",
    "```sql\n",
    "SELECT COUNT(DISTINCT company_id) num_companies_with_dup\n",
    "FROM (\n",
    "  SELECT \n",
    "    company_id, \n",
    "    title, \n",
    "    description, \n",
    "  COUNT(job_id) as job_count\n",
    "  FROM job_listings\n",
    "  GROUP BY company_id, title, description) grouped\n",
    "WHERE job_count > 1\n",
    "```\n",
    "| num_companies_with_dup |\n",
    "|------------------------|\n",
    "| 3                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd925bd",
   "metadata": {},
   "source": [
    "### 9. [Cities With Completed Trades - Robinhood Markets](https://datalemur.com/questions/completed-trades)\n",
    "Assume you're given the tables containing completed trade orders and user details in a Robinhood trading system.\n",
    "\n",
    "Write a query to retrieve the top three cities that have the highest number of completed trade orders listed in descending order. Output the city name and the corresponding number of completed trade orders.\n",
    "\n",
    "``trades`` table\n",
    "\n",
    "\n",
    "| order_id | user_id | quantity | status    | date                | price |\n",
    "|----------|---------|----------|-----------|---------------------|-------|\n",
    "| 100101   | 111     | 10       | Cancelled | 08/17/2022 12:00:00 | 9.80  |\n",
    "| 100102   | 111     | 10       | Completed | 08/17/2022 12:00:00 | 10.00 |\n",
    "| 100264   | 148     | 40       | Completed | 08/26/2022 12:00:00 | 4.80  |\n",
    "| 100305   | 300     | 15       | Completed | 09/05/2022 12:00:00 | 10.00 |\n",
    "| 100909   | 488     | 1        | Completed | 07/05/2022 12:00:00 | 6.50  |\n",
    "| 100259   | 148     | 35       | Completed | 08/25/2022 12:00:00 | 5.10  |\n",
    "| 100900   | 148     | 50       | Completed | 07/14/2022 12:00:00 | 9.78  |\n",
    "| 101432   | 265     | 10       | Completed | 08/16/2022 12:00:00 | 13.00 |\n",
    "| 102533   | 488     | 25       | Cancelled | 11/10/2022 12:00:00 | 22.40 |\n",
    "| 100565   | 265     | 2        | Completed | 09/27/2022 12:00:00 | 8.70  |\n",
    "| 100400   | 178     | 32       | Completed | 09/17/2022 12:00:00 | 12.00 |\n",
    "| 100777   | 178     | 60       | Completed | 07/25/2022 17:47:00 | 3.56  |\n",
    "\n",
    "``users`` table\n",
    "\n",
    "| user_id | city          | email                         | signup_date         |\n",
    "|---------|---------------|-------------------------------|---------------------|\n",
    "| 111     | San Francisco | rrok10@gmail.com              | 08/03/2021 12:00:00 |\n",
    "| 148     | Boston        | sailor9820@gmail.com          | 08/20/2021 12:00:00 |\n",
    "| 178     | San Francisco | harrypotterfan182@gmail.com   | 01/05/2022 12:00:00 |\n",
    "| 265     | Denver        | shadower_@hotmail.com         | 02/26/2022 12:00:00 |\n",
    "| 300     | San Francisco | houstoncowboy1122@hotmail.com | 06/30/2022 12:00:00 |\n",
    "| 488     | New York      | empire_state78@outlook.com    | 07/03/2022 12:00:00 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61677bf7",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  city,\n",
    "  COUNT(*) AS total_trade_orders\n",
    "FROM\n",
    "  trades AS t\n",
    "LEFT JOIN \n",
    "  users AS u\n",
    "ON t.user_id = u.user_id\n",
    "WHERE status = 'Completed'\n",
    "GROUP BY city\n",
    "ORDER BY total_trade_orders DESC\n",
    "LIMIT 3\n",
    "```\n",
    "\n",
    "| city          | total_trade_orders |\n",
    "|---------------|--------------------|\n",
    "| San Francisco | 4                  |\n",
    "| Boston        | 3                  |\n",
    "| Denver        | 2                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ae05e",
   "metadata": {},
   "source": [
    "### 10. [Average Review Ratings - Amazon](https://datalemur.com/questions/sql-avg-review-ratings)\n",
    "Given the reviews table, write a query to retrieve the average star rating for each product, grouped by month. The output should display the month as a numerical value, product ID, and average star rating rounded to two decimal places. Sort the output first by month and then by product ID.\n",
    "\n",
    "``reviews table``\n",
    "\n",
    "| review_id | user_id | submit_date         | product_id | stars |\n",
    "|-----------|---------|---------------------|------------|-------|\n",
    "| 6171      | 123     | 06/08/2022 00:00:00 | 50001      | 4     |\n",
    "| 7802      | 265     | 06/10/2022 00:00:00 | 69852      | 4     |\n",
    "| 5293      | 362     | 06/18/2022 00:00:00 | 50001      | 3     |\n",
    "| 6352      | 192     | 07/26/2022 00:00:00 | 69852      | 3     |\n",
    "| 4517      | 981     | 07/05/2022 00:00:00 | 69852      | 2     |\n",
    "| 2501      | 142     | 06/21/2022 00:00:00 | 12580      | 5     |\n",
    "| 4582      | 562     | 06/15/2022 00:00:00 | 12580      | 4     |\n",
    "| 2536      | 136     | 07/04/2022 00:00:00 | 11223      | 5     |\n",
    "| 1200      | 100     | 05/17/2022 00:00:00 | 25255      | 4     |\n",
    "| 2555      | 232     | 05/31/2022 00:00:00 | 25600      | 4     |\n",
    "| 2556      | 167     | 05/31/2022 00:00:00 | 25600      | 5     |\n",
    "| 1301      | 120     | 05/18/2022 00:00:00 | 25600      | 4     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10785338",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  DATE_PART('month', CAST(submit_date AS DATE)) AS month,\n",
    "  product_id,\n",
    "  ROUND(AVG(stars), 2) AS average_stars\n",
    "FROM reviews\n",
    "GROUP BY month, product_id\n",
    "ORDER BY month, product_id\n",
    "```\n",
    "\n",
    "| month | product_id | average_stars |\n",
    "|-------|------------|---------------|\n",
    "| 5     | 25255      | 4.00          |\n",
    "| 5     | 25600      | 4.33          |\n",
    "| 6     | 12580      | 4.50          |\n",
    "| 6     | 50001      | 3.50          |\n",
    "| 6     | 69852      | 4.00          |\n",
    "| 7     | 11223      | 5.00          |\n",
    "| 7     | 69852      | 2.50          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee3e12",
   "metadata": {},
   "source": [
    "##### in progress..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
